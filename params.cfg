[DEFAULT]

# agent parameters
# the size here is for both envs and agents
SIZE = 10
REPLAY_MEMORY_SIZE = 2500
MIN_REPLAY_MEMORY_SIZE = 100
MODEL_NAME = "8"
MINIBATCH_SIZE = 32
DISCOUNT = 0.95
EPISODES = 25_00
MIN_REWARD = -1.00
ACTION_SPACE_SIZE = 6

# training parameters
epsilon = 0.5
EPSILON_DECAY = 0.9995
MIN_EPSILON = 0.001
LEARNING_RATE = 0.001
TAU = 0.97

AGGREGATE_STATS_EVERY = 10  # original: 25
SAVE_MODEL_EVERY = 20  # original: 200
SHOW_PREVIEW = False

# environment parameters
N_BUILDINGS = 10
N_OBSTACLES = 10
MAX_HEIGHT = SIZE - 2
MOVE_PENALTY = 0.01
COLLISION_PENALTY = 0.25
GOAL_REWARD = 1.00
GROUND_PROX_PENALTY = 0.2
# Change this: {T(only when BINARY_ENV==F),F}
HETERO_REWARD = True
# Change this: {T,F}
BINARY_ENV = False

ELECTRIC_COST = 0.172625
VOR_HR = 1.308
DELTA_X_M = 2
DELTA_T_S = 0.2
VELOCITY = DELTA_X_M / DELTA_T_S